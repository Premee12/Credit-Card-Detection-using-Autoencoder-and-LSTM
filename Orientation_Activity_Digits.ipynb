{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Premee12/Credit-Card-Detection-using-Autoencoder-and-LSTM/blob/main/Orientation_Activity_Digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHON6y8J0568"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgMvJi6Q0_7v"
      },
      "source": [
        "<!--BOOK_INFORMATION-->\n",
        "<img align=\"left\" style=\"padding-right:10px;\" src=\"https://learning.oreilly.com/library/cover/9781491912126/\">\n",
        "\n",
        "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
        "\n",
        "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGgGXby-1Ay5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE8fB0NA1S2R"
      },
      "source": [
        "Google released its first AI Doodle on March, 2019\n",
        "\n",
        "[Sample doodle](https://www.google.com/doodles/celebrating-johann-sebastian-bach?doodle=80484806_h0xc7OKn7N4bWETVYvb9tdvg7ME1Jo0AX9Sv1gXsuUWvhVuGzB8XmBy33ldga3mKYR4p99Pd5GWL1Dsl3e8q0OWUn1-2KzU0d0179DLNK3qoK1cHUNhV-UD4ZsEi51u8u0V16u4cSKvebfhEhzaOW11MZXMoy_1HkCOBkSzgJkQkWCvYUJGInAn5uN8miMKb1B-8kPL_4HLebfEzIzXL97AC_8tw8ifSfwsWtfK4FLP5oimMDLd6-7eSm7ljFrfJa9gaGWpTyc9viMaRMYSZhyvSj67gRU26fyKN5rP8TEE4uDMm4XlTCx8PXOI0IdmVdmreB3-hSef_D9ic_DU6OAWACt7ovd-HU8gGQ2yi2WJnO3XSuMpQUNRiyEWU-wzYrbZke5hxLN665yvySBVqB7wIJ0vMXm8jyh5I6s6-QFbPTAt_W5PWIEkYVjcZZOoyq5EzT5g0UIQTHeH5M9uAXpM4cxzY2sWvljxC30pxBxrcMcjHoS7QXxGJkm9dsq_REvKmG1t93erU0Ugg3PIgMrCx7wVopcsanJLSmZk-HEOIh3fMrewoc6jJ6g6yuwpgn5JfeZMsQDAbosySSUGWXv21yqv04cf2-lUozMUrdKdB_or-bUXybzy-OFd785fWF2kiEQN7laBVc5RcoxSBRO-gkMxIqNEU2ZYK9iMyhMJTDUEFAW7JXJXF7uTJuQVo_AG4AxQJ5Vs1_TVVEZf4FltrOTHqKWrGQjrD_G9GuJIncN7U35Way0bNtvuyaT-c8aG96NcztMwFqaSPa1yhHnj9opCokPR1_oQWtqHu8Iwsg12WV2B_Qk4uco-1FQ60BSy2NF2V1qcz3f2H_xt_cjnEpW6BQJwDI2sVug8D4w0jWynMrNJU3PDe7ZKdsRzcQNzNTWtRHS9KCZnG6Q0yj1MFthRKqkWBl925J_NxD-a-7RLRliNnMJ7w8sNGRzQnPLPcFFB6oq0i-SB9LtqcSuHfUgfHD6dUTSjQhHpqrOUTnRv9YRfbjFowOmlajnQ5qHzGIVPxKzcVc0_Wql1PChBT-jf2m6AfKJoe0-HYXj0DKzVZrsu1oZ9GmtigtXfCtOq9gco0y0TtC0OGTXvDWJzfBie1lZYX9CMc_7bZdTkWjelbDiIEw0ocxvXtR_wGzPhtYvVlttIny65zuf4G9ktUj0oEq0uahejg3W-KYqGwbUjOpNlkJ_NAzAjaePdRvJ2waWLsJr_bPMokizKpae_3bY0jUkJApU6wtMIDeuKkEYepbtBIwZhW2ZjXfupXPM9HGxL_pSX_cefUi_qFJQ..&domain_name=google.com&hl=en)\n",
        "\n",
        "[Behind the Doodle](https://www.youtube.com/watch?v=XBfYPp6KF2g) (3min Youtube)\n",
        "\n",
        "[Bach-lash](https://slate.com/technology/2019/03/google-doodle-bach-ai-music-generator.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g4tUAAd1VuS"
      },
      "source": [
        "\"When a computer creates art, who is the artist$-$the computer or the programmer? At MIT, a recent exhibit of highly accomplished algorithmic art had put an awkard spin on the Harvard humanities course: _Is Art What Makes Us Human?_\"\n",
        "\n",
        "Dan Brown _Origin_, p.86"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeLpfXjB1WWQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "JckXkQix2NRS"
      },
      "source": [
        "## Application: Exploring Hand-written Digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "hu1s0kOd2NRS"
      },
      "source": [
        "To demonstrate the ML principles on a more interesting problem, let's consider one piece of the optical character recognition problem: the identification of hand-written digits.\n",
        "\n",
        "In the wild, this problem involves both locating and identifying characters in an image. Here we'll take a shortcut and use Scikit-Learn's set of pre-formatted digits, which is built into the library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DQxl9lt12NRU"
      },
      "source": [
        "### Loading and visualizing the digits data\n",
        "\n",
        "We'll use Scikit-Learn's data access interface and take a look at this data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tLkrlKem2NRU"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "digits.images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBHlazPf2mOK"
      },
      "source": [
        "import numpy as np\n",
        "digits.images[:3,:,:]\n",
        "# print(np.max(digits.images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQxPwFKX7KmA"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://upload.wikimedia.org/wikipedia/commons/0/0a/Digital_rain_animation_medium_letters_clear.gif')\n",
        "#from  From Wikimedia Commons, the free media repository"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbfGG0qx6g9L"
      },
      "source": [
        "More info on a related dataset:\n",
        "http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vV5RcitH2NRV"
      },
      "source": [
        "The images data is a three-dimensional array: 1,797 samples each consisting of an 8 × 8 grid of pixels.\n",
        "Let's visualize the first hundred of these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ogynfh6Y2NRV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
        "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
        "            transform=ax.transAxes, color='green')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "RbOLHZed2NRW"
      },
      "source": [
        "In order to work with this data within Scikit-Learn, we need a two-dimensional, ``[n_samples, n_features]`` representation.\n",
        "\n",
        "We can accomplish this by treating each pixel in the image as a feature: that is, by flattening out the pixel arrays so that we have a length-64 array of pixel values representing each digit.\n",
        "\n",
        "Additionally, we need the target array, which gives the previously determined label for each digit.\n",
        "These two quantities are built into the digits dataset under the ``data`` and ``target`` attributes, respectively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "WjKEVY_O2NRW"
      },
      "source": [
        "X = digits.data\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kMSVUZcF2NRW"
      },
      "source": [
        "y = digits.target\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "E59uPR2V2NRX"
      },
      "source": [
        "We see here that there are 1,797 samples and 64 features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yXd5Znpc2NRX"
      },
      "source": [
        "### Unsupervised learning: Dimensionality reduction\n",
        "\n",
        "We'd like to visualize our points within the 64-dimensional parameter space, but it's difficult to effectively visualize points in such a high-dimensional space.\n",
        "Instead we'll reduce the dimensions to 2, using an unsupervised method.\n",
        "Here, we'll make use of a manifold learning algorithm called *Isomap* (see [In-Depth: Manifold Learning](05.10-Manifold-Learning.ipynb)), and transform the data to two dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GBxOgQrR2NRX"
      },
      "source": [
        "from sklearn.manifold import Isomap\n",
        "iso = Isomap(n_components=2)\n",
        "iso.fit(digits.data)\n",
        "data_projected = iso.transform(digits.data)\n",
        "data_projected.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "evaoXytR2NRX"
      },
      "source": [
        "We see that the projected data is now two-dimensional.\n",
        "Let's plot this data to see if we can learn anything from its structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7LhRxBZa2NRX"
      },
      "source": [
        "plt.scatter(data_projected[:, 0], data_projected[:, 1], c=digits.target,\n",
        "            edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('jet', 10))\n",
        "plt.colorbar(label='digit label', ticks=range(10))\n",
        "plt.clim(-0.5, 9.5);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "dk3nw9PS2NRX"
      },
      "source": [
        "This plot gives us some good intuition into how well various numbers are separated in the larger 64-dimensional space. For example, zeros (in black) and ones (in purple) have very little overlap in parameter space.\n",
        "Intuitively, this makes sense: a zero is empty in the middle of the image, while a one will generally have ink in the middle.\n",
        "On the other hand, there seems to be a more or less continuous spectrum between ones and fours: we can understand this by realizing that some people draw ones with \"hats\" on them, which cause them to look similar to fours.\n",
        "\n",
        "Overall, however, the different groups appear to be fairly well separated in the parameter space: this tells us that even a very straightforward supervised classification algorithm should perform suitably on this data.\n",
        "Let's give it a try."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "adCPX-n52NRY"
      },
      "source": [
        "### Classification on digits\n",
        "\n",
        "Let's apply a classification algorithm to the digits.\n",
        "As with the Iris data previously, we will split the data into a training and testing set, and fit a Gaussian naive Bayes model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "uW31bxcw2NRZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#1. Split the data into 75% train / 25% test using train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "i0q6wZWL2NRZ"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "#2. Create a GaussianNB model and fit it on training data\n",
        "model = GaussianNB()\n",
        "model.fit(Xtrain, ytrain)\n",
        "#3. Test model performance on a held-out dataset.\n",
        "y_model = model.predict(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GV1bCxnB2NRZ"
      },
      "source": [
        "Now that we have predicted our model, we can gauge its accuracy by comparing the true values of the test set to the predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "B39_Z2Zw2NRZ"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(ytest, y_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "PUR92sEE2NRb"
      },
      "source": [
        "With even this extremely simple model, we find about 80% accuracy for classification of the digits!\n",
        "\n",
        "However, this single number doesn't tell us *where* we've gone wrong—one nice way to do this is to use the *confusion matrix*, which we can compute with Scikit-Learn and plot with Seaborn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DHQ037pw2NRb"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "mat = confusion_matrix(ytest, y_model)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
        "plt.xlabel('predicted value')\n",
        "plt.ylabel('true value');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5gslYYVX2NRc"
      },
      "source": [
        "This shows us where the mis-labeled points tend to be: for example, a large number of twos here are mis-classified as either ones or eights.\n",
        "\n",
        "Another way to gain intuition into the characteristics of the model is to plot the inputs again, with their predicted labels.\n",
        "\n",
        "We'll use green for correct labels, and red for incorrect labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "BVWNCRBH2NRd"
      },
      "source": [
        "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "\n",
        "test_images = Xtest.reshape(-1, 8, 8)\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(test_images[i], cmap='binary', interpolation='nearest')\n",
        "    ax.text(0.05, 0.05, str(y_model[i]),\n",
        "            transform=ax.transAxes,\n",
        "            color='green' if (ytest[i] == y_model[i]) else 'red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OHEpjxPN2NRd"
      },
      "source": [
        "Examining this subset of the data, we can gain insight regarding where the algorithm might be not performing optimally.\n",
        "\n",
        "To go beyond our 80% classification rate, we might move to a more sophisticated algorithm such as support vector machines (see [In-Depth: Support Vector Machines](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.07-Support-Vector-Machines.ipynb), random forests (see [In-Depth: Decision Trees and Random Forests](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.08-Random-Forests.ipynb) or another classification approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE9eQ2Mq1aMa"
      },
      "source": [
        "## Activity\n",
        "\n",
        "- Split into Break-out rooms\n",
        "- Choose an appropriate classifier\n",
        "- Train / test and display its accuracy\n",
        "- Plot a confusion matrix, if possible\n",
        "\n",
        "Hint: See the [Scikit's ML map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) to help with model selection and links to their docs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsbDBWc23OkV"
      },
      "source": [
        "### Related topics / Future work\n",
        "\n",
        "- How to select appropriate machine learning model\n",
        "- Training a model: overfit/underfit\n",
        "- Hyperparameter tuning: let the machine search for seek out the best params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulKcqYSN4gTv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}